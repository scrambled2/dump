{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkczoRRE8XZw"
      },
      "source": [
        "# **Evolutionary Prompt-Mining Jax**\n",
        "[Stable Diffusion](https://github.com/CompVis/stable-diffusion) by Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, Bj√∂rn Ommer and the [Stability.ai](https://stability.ai/) Team. [K Diffusion](https://github.com/crowsonkb/k-diffusion) by [Katherine Crowson](https://twitter.com/RiversHaveWings).\n",
        "\n",
        "The aesthetics model that is an integral part of this method was made by [Katherine Crowson](https://twitter.com/RiversHaveWings) and can be found on her [Github account](https://github.com/crowsonkb/simulacra-aesthetic-models). Some parts of the CLIP guidance is also by her.\n",
        "\n",
        "Notebook by [Magnus Petersen](https://twitter.com/Omorfiamorphism), the baseline of the notebook, setup, description, and image generation, is based on the\n",
        "[deforum](https://discord.gg/upmXXsrwZc) notebook and the [Stable Diffusion with Jax](https://huggingface.co/blog/stable_diffusion_jax) code. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0YHLndloz1U_"
      },
      "outputs": [],
      "source": [
        "#@title Install required libraries\n",
        "from IPython.display import clear_output, display\n",
        "# !pip install huggingface_hub==0.10.0 gradio\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "e5Ew5kcf0H05"
      },
      "outputs": [],
      "source": [
        "# #@title Login to the Hugging Face Hub\n",
        "# #@markdown Make sure you also have read and accept the LICENSE of the [Stable Diffusion model](https://huggingface.co/runwayml/stable-diffusion-v1-5), otherwise you may find an error\n",
        "# from huggingface_hub import notebook_login\n",
        "# !git config --global credential.helper store\n",
        "\n",
        "# notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GeLWOpZ0w7bU"
      },
      "outputs": [],
      "source": [
        "#@markdown **Model and Output Paths**\n",
        "# ask for the link\n",
        "print(\"Local Path Variables:\\n\")\n",
        "\n",
        "output_path = \"/content/output\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown **Google Drive Path Variables (Optional)**\n",
        "mount_google_drive = True #@param {type:\"boolean\"}\n",
        "force_remount = False\n",
        "\n",
        "if mount_google_drive:\n",
        "    from google.colab import drive # type: ignore\n",
        "    try:\n",
        "        drive_path = \"/content/drive\"\n",
        "        drive.mount(drive_path,force_remount=force_remount)\n",
        "        output_path_gdrive = \"/content/drive/MyDrive/AI/StableDiffusion\" #@param {type:\"string\"}\n",
        "        output_path = output_path_gdrive\n",
        "    except:\n",
        "        print(\"...error mounting drive or with drive path variables\")\n",
        "        print(\"...reverting to default path variables\")\n",
        "\n",
        "import os\n",
        "import time\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "def get_output_folder(output_path, batch_folder):\n",
        "    out_path = os.path.join(output_path,time.strftime('%Y-%m'))\n",
        "    if batch_folder != \"\":\n",
        "        out_path = os.path.join(out_path, batch_folder)\n",
        "    os.makedirs(out_path, exist_ok=True)\n",
        "    return out_path\n",
        "\n",
        "print(f\"output_path: {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !pip install diffusers transformers ftfy accelerate\n",
        " clear_output()"
      ],
      "metadata": {
        "id": "GTRykBVyRX6J"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFMtdmPeyxpi"
      },
      "outputs": [],
      "source": [
        "#@title Import required libraries\n",
        "import numpy as np\n",
        "\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "# from huggingface_hub import notebook_login\n",
        "from diffusers import FlaxStableDiffusionPipeline\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms.functional as TF\n",
        "import pandas as pd\n",
        "import os\n",
        "import gc\n",
        "import random\n",
        "import requests\n",
        "import io \n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "! git clone https://github.com/MagnusPetersen/EvoGen-Prompt-Evolution.git\n",
        "\n",
        "def image_grid(imgs, rows, cols):\n",
        "    w,h = imgs[0].size\n",
        "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
        "    for i, img in enumerate(imgs): grid.paste(img, box=(i%cols*w, i//cols*h))\n",
        "    return grid\n",
        "\n",
        "def fetch(url_or_path):\n",
        "    if str(url_or_path).startswith('http://') or str(url_or_path).startswith('https://'):\n",
        "        r = requests.get(url_or_path)\n",
        "        r.raise_for_status()\n",
        "        fd = io.BytesIO()\n",
        "        fd.write(r.content)\n",
        "        fd.seek(0)\n",
        "        return fd\n",
        "    return open(url_or_path, 'rb')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import DiffusionPipeline\n",
        "pipeline = DiffusionPipeline.from_pretrained(\"SG161222/Realistic_Vision_V2.0\", requires_safety_checker=False).to(device)\n",
        "\n",
        "def dummy_checker(images, **kwargs): return images, False\n",
        "\n",
        "pipeline.safety_checker = dummy_checker"
      ],
      "metadata": {
        "id": "__bgFWYYRyWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "i96IDgRC4Sqt"
      },
      "outputs": [],
      "source": [
        "#@title Aesthetics Helpers\n",
        "\n",
        "from torchvision.transforms import functional as TF\n",
        "import torch.nn.functional as F\n",
        "\n",
        "!git clone https://github.com/openai/CLIP\n",
        "!git clone https://github.com/crowsonkb/simulacra-aesthetic-models\n",
        "!pip install -e ./CLIP\n",
        "import sys\n",
        "sys.path.append('./CLIP')\n",
        "\n",
        "import clip\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "class MakeCutouts(nn.Module):\n",
        "    def __init__(self, cut_size, cutn, cut_pow=1.):\n",
        "        super().__init__()\n",
        "        self.cut_size = cut_size\n",
        "        self.cutn = cutn\n",
        "        self.cut_pow = cut_pow\n",
        "    def forward(self, input):\n",
        "        sideY, sideX = input.shape[2:4]\n",
        "        max_size = min(sideX, sideY)\n",
        "        min_size = min(sideX, sideY, self.cut_size)\n",
        "        cutouts = []\n",
        "        for _ in range(self.cutn):\n",
        "            size = int(torch.rand([])**self.cut_pow * (max_size - min_size) + min_size)\n",
        "            offsetx = torch.randint(0, sideX - size + 1, ())\n",
        "            offsety = torch.randint(0, sideY - size + 1, ())\n",
        "            cutout = input[:, :, offsety:offsety + size, offsetx:offsetx + size]\n",
        "            cutouts.append(F.adaptive_avg_pool2d(cutout, self.cut_size))\n",
        "        return torch.cat(cutouts)\n",
        "\n",
        "class AestheticMeanPredictionLinearModel(nn.Module):\n",
        "    def __init__(self, feats_in):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(feats_in, 1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = F.normalize(input, dim=-1) * input.shape[-1] ** 0.5\n",
        "        return self.linear(x)\n",
        "\n",
        "clip_model_name = 'ViT-B/16'\n",
        "clip_model = clip.load(clip_model_name, jit=False, device=device)[0]\n",
        "clip_model.eval().requires_grad_(False)\n",
        "\n",
        "cutn = 32\n",
        "make_cutouts = MakeCutouts(224, cutn)\n",
        "normalize = transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n",
        "                                 std=[0.26862954, 0.26130258, 0.27577711])\n",
        "\n",
        "# 512 is embed dimension for ViT-B/16 CLIP\n",
        "aes_model = AestheticMeanPredictionLinearModel(512)\n",
        "aes_model.load_state_dict(\n",
        "    torch.load(\"/content/simulacra-aesthetic-models/models/sac_public_2022_06_29_vit_b_16_linear.pth\")\n",
        ")\n",
        "\n",
        "aes_model = aes_model.to(device)\n",
        "\n",
        "artists = pd.read_csv('/content/EvoGen-Prompt-Evolution/Wordlists/artists.csv').dropna()\n",
        "genres = pd.read_csv('/content/EvoGen-Prompt-Evolution/Wordlists/genres.csv').dropna()\n",
        "words = pd.read_csv('/content/EvoGen-Prompt-Evolution/Wordlists/wordlist.csv').dropna()\n",
        "words_aes = pd.read_csv('/content/EvoGen-Prompt-Evolution/Wordlists/wordsprompt.csv').dropna()\n",
        "engrams_aes = pd.read_csv('/content/EvoGen-Prompt-Evolution/Wordlists/engramprompt.csv').dropna()\n",
        "\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HV9Y1gothcJQ"
      },
      "outputs": [],
      "source": [
        "#@title Evolution Helpers\n",
        "\n",
        "class PromptGenerator:\n",
        "    def __init__(self, population_count, prompt_length_max, prompt_length_min,\n",
        "                 artist_prop, genre_prop, custom_prop, delete_prop, add_prop, mutate_prop,\n",
        "                 shuffle_prop, cross_prop, k):\n",
        "        self.artists = artists\n",
        "        self.genres = genres\n",
        "        if use_aes_words:\n",
        "          self.words = words_aes\n",
        "        if use_aes_engrams:\n",
        "          self.words = engrams_aes\n",
        "        if use_aes_words and use_aes_engrams:\n",
        "          self.words = words_aes.append(engrams_aes)\n",
        "        if use_aes_words == False and use_aes_engrams == False:\n",
        "          self.words = words\n",
        "\n",
        "        self.custom = custom\n",
        "        self.population_count = population_count\n",
        "        self.prompt_length_max = prompt_length_max \n",
        "        self.prompt_length_min = prompt_length_min\n",
        "\n",
        "        self.artist_prop = artist_prop \n",
        "        self.genre_prop = genre_prop \n",
        "        self.custom_prop = custom_prop\n",
        "\n",
        "        self.word_prop = 1 - self.artist_prop - self.genre_prop\n",
        "        self.delete_prop = delete_prop \n",
        "        self.add_prop = add_prop \n",
        "        \n",
        "        self.mutate_prop = mutate_prop \n",
        "        self.shuffle_prop = shuffle_prop \n",
        "        self.cross_prop = cross_prop \n",
        "        self.k = k \n",
        "\n",
        "        self.fittness_history = []\n",
        "\n",
        "    def initialize_prompt_population(self):\n",
        "        #initialize the prompt population by randomly selecting words from artists, genres, and words dictionaries\n",
        "        prompt_population = []\n",
        "        for i in range(self.population_count):\n",
        "            prompt = []\n",
        "            for j in range(np.random.randint(self.prompt_length_min, self.prompt_length_max)):\n",
        "                #pic based on artist_prop, genre_prop, and word_prop probabilities which dataframe to select from\n",
        "                rand_num = np.random.random()\n",
        "                if rand_num < self.artist_prop:\n",
        "                    prompt.append(self.artists.sample(1).artist.values[0])\n",
        "                elif rand_num < self.artist_prop + self.genre_prop:\n",
        "                    prompt.append(self.genres.sample(1).genre.values[0])\n",
        "                elif rand_num < self.artist_prop + self.genre_prop + self.custom_prop:\n",
        "                    prompt.append(self.custom.sample(1).custom.values[0])\n",
        "                else:\n",
        "                    prompt.append(self.words.sample(1).word.values[0])\n",
        "            prompt_population.append(prompt)\n",
        "            if require_custom_words:\n",
        "              if any(word in self.custom for word in prompt):\n",
        "                pass\n",
        "              else:\n",
        "                #select min_custom_words from custom list and swap them in\n",
        "                custom_words = self.custom.sample(min_custom_words).custom.values\n",
        "                for word in custom_words:\n",
        "                    prompt[np.random.randint(len(prompt))] = word\n",
        "        self.prompt_population = prompt_population\n",
        "\n",
        "    def selection(self, scores):\n",
        "        selection_ix = np.random.randint(self.population_count)\n",
        "        for ix in np.random.randint(0, self.population_count, self.k-1):\n",
        "            if scores[ix] > scores[selection_ix]:\n",
        "                selection_ix = ix\n",
        "        return self.prompt_population[selection_ix]\n",
        "\n",
        "    def cross_over(self, prompt_1, prompt_2):\n",
        "        c1, c2 = prompt_1, prompt_2\n",
        "        rand_num = np.random.random()\n",
        "        if rand_num < self.cross_prop:\n",
        "            if len(prompt_2) ==0:\n",
        "              prompt_index = 0\n",
        "            else:\n",
        "              prompt_index = np.random.randint(0, min(len(prompt_1), len(prompt_2)))\n",
        "            c1 = prompt_1[:prompt_index] + prompt_2[prompt_index:]\n",
        "            c2 = prompt_2[:prompt_index] + prompt_1[prompt_index:]\n",
        "        return [c1, c2]\n",
        "\n",
        "    def mutate_prompts(self, prompt):\n",
        "        if (len(prompt) == 0):\n",
        "          prompt_index = 0\n",
        "          rand_num = np.random.random()\n",
        "          if rand_num < self.artist_prop:\n",
        "              prompt.insert(prompt_index, self.artists.sample(1).artist.values[0])\n",
        "          elif rand_num < self.artist_prop + self.genre_prop:\n",
        "              prompt.insert(prompt_index, self.genres.sample(1).genre.values[0])\n",
        "          elif rand_num < self.artist_prop + self.genre_prop + self.custom_prop:\n",
        "              prompt.insert(prompt_index, self.custom.sample(1).custom.values[0])\n",
        "          else:\n",
        "              prompt.insert(prompt_index, self.words.sample(1).word.values[0])\n",
        "\n",
        "        for i in range(len(prompt)):\n",
        "            rand_num = np.random.random()\n",
        "            if rand_num < self.mutate_prop:\n",
        "                rand_num = np.random.random()\n",
        "                if rand_num < self.artist_prop:\n",
        "                    prompt[i] = self.artists.sample(1).artist.values[0]\n",
        "                elif rand_num < self.artist_prop + self.genre_prop:\n",
        "                    prompt[i] = self.genres.sample(1).genre.values[0]\n",
        "                elif rand_num < self.artist_prop + self.genre_prop + self.custom_prop:\n",
        "                    prompt[i] = self.custom.sample(1).custom.values[0]\n",
        "                else:\n",
        "                    prompt[i] = self.words.sample(1).word.values[0]\n",
        "\n",
        "\n",
        "        delete_count = np.random.binomial(len(prompt), self.delete_prop)\n",
        "        if len(prompt) - delete_count < 2:\n",
        "            delete_count = len(prompt) - 2\n",
        "\n",
        "        prompt = np.delete(prompt, np.random.randint(len(prompt), size=delete_count)).tolist()\n",
        "        \n",
        "        for i in range(len(prompt)):\n",
        "            rand_num = np.random.random()\n",
        "            if rand_num < self.add_prop:\n",
        "                rand_num = np.random.random()\n",
        "                if rand_num < self.artist_prop:\n",
        "                    prompt.insert(i, self.artists.sample(1).artist.values[0])\n",
        "                elif rand_num < self.artist_prop + self.genre_prop:\n",
        "                    prompt.insert(i, self.genres.sample(1).genre.values[0])\n",
        "                elif rand_num < self.artist_prop + self.genre_prop + self.custom_prop:\n",
        "                    prompt.insert(i, self.custom.sample(1).custom.values[0])\n",
        "                else:\n",
        "                    prompt.insert(i, self.words.sample(1).word.values[0])\n",
        "            \n",
        "        rand_num = np.random.random()\n",
        "        if rand_num < self.shuffle_prop:\n",
        "            prompt = np.random.permutation(prompt).tolist()\n",
        "            \n",
        "        return prompt\n",
        "\n",
        "    def create_next_generation(self, scores):\n",
        "        selected = [self.selection(scores) for _ in range(self.population_count)]\n",
        "        children = []\n",
        "        for i in range(0, self.population_count, 2):\n",
        "            prompt_1, prompt_2 = selected[i], selected[i+1]\n",
        "            for c in self.cross_over(prompt_1, prompt_2):\n",
        "                c = self.mutate_prompts(c)\n",
        "                children.append(c)\n",
        "\n",
        "        filtered_children = []\n",
        "        for elem in children:\n",
        "            if elem not in filtered_children:\n",
        "                filtered_children.append(elem)\n",
        "\n",
        "        children = filtered_children\n",
        "\n",
        "        missing_prompts = self.population_count - len(children)\n",
        "        print(\"The following number of duplicate prompts had to be replaced with random ones:\"+str(missing_prompts))\n",
        "        for i in range(missing_prompts):\n",
        "            prompt = []\n",
        "            for j in range(np.random.randint(self.prompt_length_min, self.prompt_length_max)):\n",
        "                rand_num = np.random.random()\n",
        "                if rand_num < self.artist_prop:\n",
        "                    prompt.append(self.artists.sample(1).artist.values[0])\n",
        "                elif rand_num < self.artist_prop + self.genre_prop:\n",
        "                    prompt.append(self.genres.sample(1).genre.values[0])\n",
        "                else:\n",
        "                    prompt.append(self.words.sample(1).word.values[0])\n",
        "            children.append(prompt)\n",
        "        \n",
        "        if require_custom_words:\n",
        "            for prompt in children:\n",
        "                if any(word in self.custom for word in prompt):\n",
        "                    pass\n",
        "                else:\n",
        "                    custom_words = self.custom.sample(min_custom_words).custom.values\n",
        "                    for word in custom_words:\n",
        "                        prompt[np.random.randint(len(prompt))] = word\n",
        "        self.prompt_population = children\n",
        "\n",
        "    def population_as_string(self):\n",
        "        return [' '.join(prompt) for prompt in self.prompt_population]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-WjGakJqhlIj"
      },
      "outputs": [],
      "source": [
        "#Create your custom word list from which the evolutionary algorithm samples words. You can set a sampling probability but can also enforce a certain number of these words to be in the prompts.\n",
        "custom_words = [\"Zeiss Lens\", \"Leica Lens\", \"Model\"]\n",
        "custom = pd.DataFrame(custom_words, columns=[\"custom\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "g4LUKd5vhl9X",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown **Evolutionary Algorithm Settings**\n",
        "\n",
        "#@markdown General population settings, such as how many generations the algorithm runs for, how many prompts there are in each generation, and the word length range of the prompts.\n",
        "generations = 25 #@param\n",
        "n_samples = 8\n",
        "population_count = 400 #@param\n",
        "population_count = int(n_samples*(population_count//n_samples + 1))\n",
        "prompt_length_max = 25 #@param\n",
        "prompt_length_min = 3 #@param\n",
        "#@markdown Probability to sample from one of the word lists when adding or mutating a word. The difference between the sum of the three custom lists and 1 is the probability to sample from the English dictionary word list.\n",
        "artist_prop = 0.04 #@param\n",
        "genre_prop = 0.08 #@param\n",
        "custom_prop = 0.0 #@param\n",
        "#@markdown require_custom_words turns the custom_words_list into a list where a given number of words from that list, determined by min_custom_words, have to be included in the prompts.\n",
        "require_custom_words  = True #@param {type:\"boolean\"}\n",
        "min_custom_words = 2 #@param\n",
        "#@markdown Decide which list to use if the genre, custom and artists list are not selected from sampling. Use either a list from high scoring prompts, 2/3-grams of those prompts of both. If none are selected use a complete english dictionary.\n",
        "use_aes_words = False #@param {type:\"boolean\"}\n",
        "use_aes_engrams = False #@param {type:\"boolean\"}\n",
        "#@markdown Generation evolution settings including the probability to delete, add and swap out each word for a new one from the dictionary.\n",
        "delete_prop = 0.1 #@param\n",
        "add_prop = 0.105 #@param\n",
        "mutate_prop = 0.15 #@param\n",
        "shuffle_prop = 0.1 #@param\n",
        "#@markdown Generation evolution settings for the new generation parent selection and breeding. The cross-over probability is the probability of the parents swapping prompt parts. K denotes the rounds in the tournament selection process. A higher K value means fewer parents generate the next generation, this means a higher score increase but less diversity in the prompts.\n",
        "cross_prop = 0.8 #@param\n",
        "k = 6 #@param\n",
        "#@markdown Cutoff score to save the image and prompt and display it.\n",
        "cutoff = 6.2 #@param\n",
        "#@markdown True if you want to guide the evolution with an additional prompt and not just aesthetics\n",
        "use_prompt = True #@param {type:\"boolean\"}\n",
        "prompt = \"A photo portrait of \" #@param {type:\"string\"}\n",
        "if use_prompt:\n",
        "  encoding_txt = clip_model.encode_text(clip.tokenize(prompt).to(device)).float()\n",
        "#@markdown True if you want to guide the evolution with an additional image prompt and not just aesthetics\n",
        "use_img = False #@param {type:\"boolean\"}\n",
        "img_url = \"https://pbs.twimg.com/media/FeThOokUAAAJK-m?format=jpg&name=4096x4096\" #@param {type:\"string\"}\n",
        "if use_img:\n",
        "  img = Image.open(fetch(img_url)).convert('RGB')\n",
        "  img = TF.resize(img, min(224, 224, *img.size), transforms.InterpolationMode.LANCZOS)\n",
        "  batch = make_cutouts(TF.to_tensor(img).unsqueeze(0).to(device))\n",
        "  encoding_img = clip_model.encode_image(normalize(batch)).float()\n",
        "#@markdown The weight of prompt & image prompt. For instance 0.6 means the score is the result of 60% prompt+image prompt and 40% aesthetics\n",
        "prompt_weigth = 0.5 #@param\n",
        "#@markdown **Save & Display Settings**\n",
        "batch_name = \"StableEvoImgPromptV53\" #@param {type:\"string\"}\n",
        "outdir = get_output_folder(output_path, batch_name)\n",
        "save_samples = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown **Image Settings**\n",
        "W = 768 #@param\n",
        "H = 768 #@param\n",
        "W, H = map(lambda x: x - x % 64, (W, H))  # resize to integer multiple of 64\n",
        "\n",
        "#@markdown **Sampling Settings**\n",
        "num_inference_steps = 25 #@param {type:\"integer\"}\n",
        "seed = -1 #@param {type:\"integer\"}\n",
        "#@markdown `-1` will set a random seed. You can replace that to any integer for reproducible results\n",
        "\n",
        "# def filtered_with_scores(special_cos_dist, cos_dist, images, safety_model_params):\n",
        "#   return images, [False]\n",
        "# pipeline.safety_checker.filtered_with_scores = filtered_with_scores\n",
        "\n",
        "n_samples = torch.cuda.device_count()\n",
        "\n",
        "prompt_generator = PromptGenerator(population_count, prompt_length_max, prompt_length_min,\n",
        "                                  artist_prop, genre_prop, custom_prop, delete_prop, add_prop, mutate_prop,\n",
        "                                  shuffle_prop, cross_prop, k)\n",
        "prompt_generator.initialize_prompt_population()\n",
        "\n",
        "mean_score = []\n",
        "mean_loss_prompt = []\n",
        "best_score = []\n",
        "mean_prompt_length = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxO5p4NPhqsp"
      },
      "outputs": [],
      "source": [
        "#@title Evolution Loop\n",
        "\n",
        "def plot_fittness_history():\n",
        "  plt.figure(figsize=(14,7))\n",
        "  plt.rcParams.update({'font.size': 12})\n",
        "  plt.subplot(2,2,1)\n",
        "  plt.plot(mean_score)\n",
        "  plt.title(\"Mean Score\")\n",
        "  plt.xlabel(\"Generation\")\n",
        "  plt.ylabel(\"Score\")\n",
        "  plt.subplot(2,2,2)\n",
        "  plt.plot(best_score)\n",
        "  plt.title(\"Best Score\")\n",
        "  plt.xlabel(\"Generation\")\n",
        "  plt.ylabel(\"Score\")\n",
        "  plt.subplot(2,2,3)\n",
        "  plt.hist(scores[::, 0], bins=20)\n",
        "  plt.title(\"Score Histogram\")\n",
        "  plt.xlabel(\"Score\")\n",
        "  plt.ylabel(\"Frequency\")\n",
        "  plt.subplot(2,2,4)\n",
        "  plt.plot(mean_prompt_length)\n",
        "  plt.title(\"Mean Prompt Length\")\n",
        "  plt.xlabel(\"Generation\")\n",
        "  plt.ylabel(\"Prompt Length\")\n",
        "  plt.tight_layout()\n",
        "  if use_prompt or use_img:\n",
        "    plt.figure(figsize=(14,3))\n",
        "    plt.rcParams.update({'font.size': 12})\n",
        "    plt.subplot(1,1,1)\n",
        "    #plot the mean prompt score over time\n",
        "    plt.plot(mean_loss_prompt)\n",
        "    plt.title(\"Prompt Loss\")\n",
        "    plt.xlabel(\"Generation\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.tight_layout()\n",
        "  plt.figure(figsize=(14,7))\n",
        "  plt.rcParams.update({'font.size': 12})\n",
        "  plt.subplot(1,1,1)\n",
        "  plt.bar(most_frequent_words.word, most_frequent_words.frequency)\n",
        "  plt.xticks(rotation=90)\n",
        "  plt.title(\"Most Frequent Words\")\n",
        "  plt.xlabel(\"Word\")\n",
        "  plt.ylabel(\"Count\")\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "def plot_top_9():\n",
        "  top_9idx = torch.flip(np.argsort(scores)[-9:], (0,)).tolist()\n",
        "  print(*[prompts[i] for i in top_9idx], sep = \"\\n\")\n",
        "  with open(os.path.join(gen_path, \"best_9_prompts.txt\"), 'w') as f:\n",
        "    f.write('\\n'.join([prompts[i] for i in top_9idx]))\n",
        "  top_9 = image_population[top_9idx]\n",
        "  top_9 = torch.cat([top_9[i:i+3] for i in range(0, 9, 3)], dim=2)\n",
        "  top_9 = torch.cat([top_9[i:i+1] for i in range(0, 3, 1)], dim=3)\n",
        "  best_img = transforms.ToPILImage()(top_9[0])\n",
        "  display(best_img)\n",
        "  best_img.save(os.path.join(gen_path, \"best_9.png\"))\n",
        "\n",
        "def shard_and_gen_images(prompts):\n",
        "  if(seed == -1):\n",
        "    random_int = random.randint(0, 2147483647)\n",
        "    real_seed = random_int\n",
        "  else:\n",
        "    real_seed = seed\n",
        "  prng_seed = torch.manual_seed(real_seed)\n",
        "  images = pipeline(prompts, num_inference_steps=num_inference_steps, generator=prng_seed, height = H, width = W, output_type=np.array).images\n",
        "  return images, real_seed\n",
        "\n",
        "def spherical_dist_loss(x, y):\n",
        "    x = F.normalize(x, dim=-1)\n",
        "    y = F.normalize(y, dim=-1)\n",
        "    return (x - y).norm(dim=-1).div(2).arcsin().pow(2).mul(2)\n",
        "\n",
        "def fittness_function(images):\n",
        "  clip_preped_images = torch.zeros(size = (n_samples, 3, 224, 224))\n",
        "  for i in range(len(images)):\n",
        "    img = TF.resize(images[i], 224, transforms.InterpolationMode.LANCZOS)\n",
        "    img = TF.center_crop(img, (224,224))\n",
        "    img = TF.to_tensor(img).to(device)\n",
        "    img = normalize(img)\n",
        "    clip_preped_images[i] = img\n",
        "\n",
        "  clip_image_embed = F.normalize(\n",
        "      clip_model.encode_image(clip_preped_images.to(device)).float(),\n",
        "      dim=-1)\n",
        "  scores = aes_model(clip_image_embed).mean(axis = 1)\n",
        "  clip_score = torch.zeros(size =(n_samples,))\n",
        "  if use_prompt:\n",
        "    dists = spherical_dist_loss(clip_image_embed.unsqueeze(1), encoding_txt.unsqueeze(0))\n",
        "    dists = dists.view([1, n_samples, -1])\n",
        "    clip_score += dists.sum(2).mean(0).cpu()\n",
        "  if use_img:\n",
        "    dists = spherical_dist_loss(clip_image_embed.unsqueeze(1), encoding_img.unsqueeze(0))\n",
        "    dists = dists.view([cutn, n_samples, -1])\n",
        "    clip_score += dists.sum(2).mean(0).cpu()\n",
        "  return scores, clip_score\n",
        "\n",
        "with torch.no_grad():\n",
        "  for i in range(generations):\n",
        "    gen_path = get_output_folder(output_path, batch_name)+'/gen_'+str(i)\n",
        "    os.makedirs(gen_path, exist_ok=True)\n",
        "    os.makedirs(gen_path+\"/best\", exist_ok=True)\n",
        "  \n",
        "    prompts = prompt_generator.population_as_string()\n",
        "    image_population = torch.zeros(size = (prompt_generator.population_count, 3, H, W))\n",
        "    scores = torch.zeros(prompt_generator.population_count, 2)\n",
        "    displayed_img_count = 0\n",
        "\n",
        "    for j in range(0, prompt_generator.population_count, n_samples):\n",
        "      gc.collect()\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "      images, current_seed = shard_and_gen_images(prompts[j:(j+n_samples)])\n",
        "      images_pil = pipeline.numpy_to_pil(np.asarray(images.reshape((n_samples,) + images.shape[-3:])))\n",
        "      aes_score, prompt_score = fittness_function(images_pil)\n",
        "      scores[j:(j+n_samples), 0] = aes_score\n",
        "      scores[j:(j+n_samples), 1] = prompt_score\n",
        "\n",
        "      for k in range(len(images)):\n",
        "        # image_population[j+k] = torch.tensor(np.float32(images[k]))[0].permute([2, 0, 1])\n",
        "        image_population[j+k] = torch.tensor(np.float32(images[k])).permute([2, 0, 1])\n",
        "      \n",
        "        if save_samples:\n",
        "            filename = prompts[j+k]+\".png\"\n",
        "            images_pil[k].save(os.path.join(gen_path, filename))\n",
        "\n",
        "        if scores[j+k, 0] >= cutoff:\n",
        "          filename_length = min(150, len(prompts[j+k]))\n",
        "          images_pil[k].save(gen_path+'/best/'+prompts[j+k][:filename_length]+'.png')\n",
        "          with open(gen_path+'/best/'+prompts[j+k][:filename_length]+'.txt', 'w') as f:\n",
        "            f.write(prompts[j+k])\n",
        "            f.write('\\n')\n",
        "            f.write(str(current_seed))\n",
        "          if save_samples == False:\n",
        "            print(prompts[j+k])\n",
        "            display(images_pil[k])\n",
        "            displayed_img_count += 1\n",
        "            if displayed_img_count >= 32:\n",
        "              clear_output(wait=True)\n",
        "              displayed_img_count = 0\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    mean_score.append(scores[::, 0].mean().item())\n",
        "    mean_loss_prompt.append(scores[::, 1].mean().item())\n",
        "    best_score.append(max(scores[::, 0]).item())\n",
        "    mean_prompt_length.append(np.mean([len(prompt) for prompt in prompt_generator.prompt_population]))\n",
        "    most_frequent_words = pd.DataFrame(sum(prompt_generator.prompt_population, []), columns = ['word']).word.value_counts().head(20).reset_index()\n",
        "    most_frequent_words.columns = ['word', 'frequency']\n",
        "\n",
        "    plot_fittness_history()\n",
        "    if use_prompt or use_img:\n",
        "      scores[::, 0] = (scores[::, 0] - scores[::, 0].min()) / (scores[::, 0].max() - scores[::, 0].min())\n",
        "      scores[::, 1] = torch.abs((scores[::, 1] - scores[::, 1].min()) / (scores[::, 1].max() - scores[::, 1].min()) - 1)\n",
        "      scores = prompt_weigth*scores[::, 0] + (1-prompt_weigth)*scores[::, 1]\n",
        "    else:\n",
        "      scores = scores[::, 0]\n",
        "    plot_top_9()\n",
        "\n",
        "    prompt_generator.create_next_generation(scores)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "9650cb4e16cdd4a8e8e2d128bf38d875813998db22a3c986335f89e0cb4d7bb2"
      }
    },
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}